![image](https://github.com/user-attachments/assets/6e30f53b-3e33-4241-b36b-e08637cf9412)
Models used:
 1. CNN model to extract features from the image
 2. RNN model to generate text based description based on the extracted features.

Features:
1. Deep Learning-Based Caption Generation: Utilizes a combination of CNNs for image feature extraction and LSTM for sequential text generation, ensuring accurate and context-aware captions.
2. Bidirectional LSTM for Improved Context Understanding: Enhances caption quality by processing sequences in both forward and backward directions, capturing dependencies from both past and future words.
3. Word Embeddings for Text Representation: Converts word indices into dense vector representations, improving the modelâ€™s ability to understand semantic relationships between words.

Dataset: https://www.kaggle.com/datasets/eeshawn/flickr30k
The Flickr dataset has around 30k images and captions.The selected 30k image dataset consists of images from 6 different Flickr groups covering different locations and situations.
